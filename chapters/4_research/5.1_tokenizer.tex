\paragraph{StreamReader}: The kernel uses a tokenizer in order to split the vis file stream into meaningful tokens. The tokenizer in turn uses a stream reader that helps it reading a file content character by character. I have followed Mihai Bazon's approach\cite{bazon16}. He suggests a function that returns the 4 methods:

\begin{itemize}
    \item peek(), returns the next character in the string but does not increment the internal pointer;
    \item next(), returns the next character in the string and increments the internal pointer by one;
    \item eof(), returns true if the en of the string has been reached;
    \item croak(message), throws an error with a given message;
\end{itemize}

\paragraph{The Tokenizer} is a function that returns the same set of methods as the Input Stream but instead of returning simple characters, the \texttt{peek()} and the \texttt{next()} methods return tokens. A token is an object with the properties type and value. Our tokenizer can produce tokens similar to those in listing~\ref{lst:tokenExamples}:

\begin{lstlisting}[
    caption={example of tokens possibly produced by the tokenizer},
    label={lst:tokenExamples}
]
{type:'id', value:'someValue'}
{type:'str', value:'Hello World!'}
{type:'num', value:0}
{type:'op', value:'-<'}
{type:'datetime', value:<momentJS Object>}
{type:'path', value:<path Object>}
{type:'separator', value:'--'}
{type:'pathSeparator', value:'!'}
{type:'EOL', value:'\n'}
\end{lstlisting}

The main idea behind the tokenizer is to look at the current character by invoking the peek method and determinate what kind of token must be produced. Through the readNext function in listing~\ref{lst:tokenizerReadNext}, the tokenization process will be ``routed'' into one of the more specialized methods that both finish to scan and evaluate the different tokens. The same tokenizer is used for both the vis and the vism file. The 

\lstinputlisting[
    caption={The readNext function handles the main logic behind the tokenizer by routing the process into the appropriate state by looking up the next first character.},
    label={lst:tokenizerReadNext}
]{code/readNext.js}

Listing~\ref{lst:tokenizerReadNext} shows how the ``readNext'' function dispatches the tokenization process into one of the more specialized functions:
\begin{itemize}
    \item it skips all white characters
    \item it returns \texttt{null} if input.peek() points at the end of the source stream
    \item it skips a comment if input.peek() returns the comment symbol ``\textquotesingle''
    \item it reads a datetime if input.peek() returns the sharp symbol ``\#''
    \item it reads a number if input.peek() returns one of the characters representing the start of a digit. The rules defining the start of a digit are written in the ``isDigit'' function.
    \item it reads an identifier or a path if input.peek() returns one of the characters representing the start of an identifier. The rules defining the start of an identifier are written in the ``isIdStart'' function.
    \item it reads an end of line if input.peek() meets the end of line symbol ``\\n''. 
    \item it reads an operator if input.peek() meets an operator symbol as being defined by the ``isOpChar'' function.
\end{itemize}